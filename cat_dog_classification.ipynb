{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog=[]\n",
    "cat=[]\n",
    "dog=[]\n",
    "b=[]\n",
    "# a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/images/dog/{1} (1).jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "# print(a.flatten())\n",
    "for i in range(1,101):\n",
    "    a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/DL/archive/training_set/training_set/dogs/dog.{i}.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    img2=Image.fromarray(a)\n",
    "    img2=img2.resize((512,350))\n",
    "    a=np.asanyarray(img2)\n",
    "    a=a.tolist()\n",
    "    dog.append(a)\n",
    "    b.append(0)\n",
    "\n",
    "for i in range(1,101):\n",
    "    a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/DL/archive/training_set/training_set/cats/cat.{i}.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    img2=Image.fromarray(a)\n",
    "    img2=img2.resize((512,350))\n",
    "    a=np.asanyarray(img2)\n",
    "    a=a.tolist()\n",
    "    dog.append(a)\n",
    "    b.append(1)\n",
    "# print(np.array(cat_dog).shape)\n",
    "# data={\"a\":cat_dog,\"b\":b}\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv(\"cat_dog.csv\")\n",
    "# cat_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(dog))\n",
    "# aaaa=np.array(dog)\n",
    "# print(type(aaaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(aaaa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa=np.array([1,2])\n",
    "# bbb=np.array([1,2])\n",
    "# print(np.concatenate([cat,dog]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Convolution2D(64,(3,4),input_shape=(350,512,1),activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D((2,1)))\n",
    "\n",
    "model.add(keras.layers.Convolution2D(128,(3,4),activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D((2,1)))\n",
    "\n",
    "model.add(keras.layers.Convolution2D(2,(3,4),activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D((2,1)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(16,(4,4),activation=tf.nn.relu,input_shape()),\n",
    "#     tf.keras.layers.Flatten(input_shape=(512, 350)),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(2)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=dog\n",
    "train_labels=b\n",
    "# print(train_images[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "\t\t\t\t\trescale=1./255,\n",
    "\t\t\t\t\trotation_range=30,\n",
    "\t\t\t\t\tshear_range=0.3,\n",
    "\t\t\t\t\tzoom_range=0.4,\n",
    "\t\t\t\t\twidth_shift_range=0.4,\n",
    "\t\t\t\t\theight_shift_range=0.4,\n",
    "\t\t\t\t\thorizontal_flip=True,\n",
    "\t\t\t\t\tfill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input to `.fit()` should have rank 4. Got array with shape: (200, 350, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\ML\\DL\\cat_dog_classification.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/ML/DL/cat_dog_classification.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_data_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/ML/DL/cat_dog_classification.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m validation_data_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/ML/DL/cat_dog_classification.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39;49mfit(train_images)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:2088\u001b[0m, in \u001b[0;36mImageDataGenerator.fit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m   2086\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   2087\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m-> 2088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput to `.fit()` should have rank 4. Got array with shape: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2090\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m   2091\u001b[0m     )\n\u001b[0;32m   2092\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_axis] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m}:\n\u001b[0;32m   2093\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2094\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected input to be images (as Numpy array) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2095\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfollowing the data format convention \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2105\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m channels).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2106\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (200, 350, 512)"
     ]
    }
   ],
   "source": [
    "\n",
    "img_height,img_width = 512,250\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_data_dir = 'Training'\n",
    "validation_data_dir = 'Validation'\n",
    "\n",
    "train_generator = train_datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/7 [===>..........................] - ETA: 6:36 - loss: 20.5704 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "cat_dog=[]\n",
    "cat=[]\n",
    "dog=[]\n",
    "b=[]\n",
    "# a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/images/dog/{1} (1).jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "# print(a.flatten())\n",
    "for i in range(12,23):\n",
    "    a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/DL/archive/training_set/training_set/dogs/dog.{i}.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    a=a.tolist()\n",
    "    dog.append(a)\n",
    "    b.append(0)\n",
    "\n",
    "for i in range(12,23):\n",
    "    a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/DL/archive/training_set/training_set/cats/cat.{i}.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    a=a.tolist()\n",
    "    cat.append(a)\n",
    "    b.append(1)\n",
    "print(np.array(cat_dog).shape)\n",
    "data={\"a\":cat_dog,\"b\":b}\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv(\"cat_dog.csv\")\n",
    "# cat_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog=[]\n",
    "cat=[]\n",
    "dog=[]\n",
    "b=[]\n",
    "# a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/images/dog/{1} (1).jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "# print(a.flatten())\n",
    "for i in range(12,23):\n",
    "    a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/DL/archive/training_set/training_set/dogs/dog.{i}.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    img2=Image.fromarray(a)\n",
    "    img2=img2.resize((512,350))\n",
    "    a=np.asanyarray(img2)\n",
    "    a=a.tolist()\n",
    "    dog.append(a)\n",
    "    b.append(0)\n",
    "\n",
    "for i in range(12,23):\n",
    "    a=cv2.imread(f\"C:/Users/Admin/Desktop/ML/DL/archive/training_set/training_set/cats/cat.{i}.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    img2=Image.fromarray(a)\n",
    "    img2=img2.resize((512,350))\n",
    "    a=np.asanyarray(img2)\n",
    "    a=a.tolist()\n",
    "    cat.append(a)\n",
    "    b.append(1)\n",
    "# print(np.array(cat_dog).shape)\n",
    "# data={\"a\":cat_dog,\"b\":b}\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv(\"cat_dog.csv\")\n",
    "# cat_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=np.concatenate([dog,cat]).tolist()\n",
    "test_labels=b\n",
    "# print(train_images[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 3s - loss: 10.6514 - accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
